{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wasserstein GAN tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4dfff8d6f3274d0b8a3384bf2fe976e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fd8c3363ea24223bedf2fb88d19f690",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cf434a12c9f46318e9550e32740512f",
              "IPY_MODEL_39e2a871f18c47a1b494ba2f86280672"
            ]
          }
        },
        "8fd8c3363ea24223bedf2fb88d19f690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cf434a12c9f46318e9550e32740512f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac89cc7257f24a5d9ff6c1dd2966fb2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 117,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b86b1bfcad143da98b86666d36bb872"
          }
        },
        "39e2a871f18c47a1b494ba2f86280672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93c2668a9e394c88a320c55adf85968b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15% 17/117 [00:40&lt;03:59,  2.39s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_950759505b61437ba559943a7e0a8cb5"
          }
        },
        "ac89cc7257f24a5d9ff6c1dd2966fb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b86b1bfcad143da98b86666d36bb872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93c2668a9e394c88a320c55adf85968b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "950759505b61437ba559943a7e0a8cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/Wasserstein-GAN-Tensorflow-2/blob/master/Wasserstein_GAN_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Mvn1V30ejH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "b80b0dc8-32d0-4721-972f-beac04d06321"
      },
      "source": [
        "!pip install tensorflow==2.0.0\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import pandas as pd\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "from tqdm.autonotebook import tqdm\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA4TqJBOXXIg",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate for Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJZ_cnp9V-Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_learning_rate=0.0001\n",
        "disc_learning_rate = 0.0002 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n15AvPFO05gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.RMSprop(gen_learning_rate)      #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(disc_learning_rate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:33.803523Z",
          "start_time": "2019-05-14T06:31:33.714599Z"
        },
        "colab_type": "code",
        "id": "Ypym6ZAESYbx",
        "colab": {}
      },
      "source": [
        "TRAIN_BUF=60000\n",
        "BATCH_SIZE=512\n",
        "TEST_BUF=10000\n",
        "DIMS = (28,28,1)\n",
        "N_TRAIN_BATCHES =int(TRAIN_BUF/BATCH_SIZE)\n",
        "N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:38.044471Z",
          "start_time": "2019-05-14T06:31:33.805821Z"
        },
        "colab_type": "code",
        "id": "xhqU6sqiSYbz",
        "colab": {}
      },
      "source": [
        "# load dataset\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# split dataset\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\n",
        "    \"float32\"\n",
        ") / 255.0\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "# batch datasets\n",
        "train_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_images)\n",
        "    .shuffle(TRAIN_BUF)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "test_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_images)\n",
        "    .shuffle(TEST_BUF)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOoYuK_jR9rH",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxhmgOa0_7c",
        "colab_type": "text"
      },
      "source": [
        "#### Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator():\n",
        "  generator = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=7 * 7 * 64, activation=\"relu\"),\n",
        "    tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.Conv2DTranspose(\n",
        "        filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"sigmoid\"\n",
        "    )])\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt2rTP7hSFt4",
        "colab_type": "text"
      },
      "source": [
        "#### Discriminator Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_discriminator():\n",
        "  discriminator = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=DIMS),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "  return discriminator\n",
        "\n",
        "number_of_disc_layers = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rIdAYRhHgGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = get_generator()\n",
        "discriminator = get_discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYGiMY4QeVrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss(train_x):\n",
        "  x  = tf.random.normal([train_x.shape[0], 1, 1, 64])\n",
        "\n",
        "  real_output = discriminator(train_x)\n",
        "  fake_output = discriminator(generator(x))\n",
        "  disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)\n",
        "  gen_loss = -tf.reduce_mean(fake_output)\n",
        "\n",
        "  return disc_loss, gen_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-t76sYBtlP1",
        "colab_type": "text"
      },
      "source": [
        "### GAN Training functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WE_JS7kgA1W-",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(train_x,n_steps=4):\n",
        "  x = tf.random.normal([train_x.shape[0], 1, 1, 64])\n",
        "  for i in range(n_steps):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_output = discriminator(train_x)\n",
        "      fake_output = discriminator(generator(x))\n",
        "      \n",
        "      disc_loss = -tf.reduce_mean(real_output) + tf.reduce_mean(fake_output)\n",
        "\n",
        "      \n",
        "      #if tf.math.is_nan(disc_loss) == False:\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "      t=0\n",
        "      for t in range(number_of_disc_layers):\n",
        "        y = tf.clip_by_value(discriminator.trainable_weights[t],clip_value_min=-0.05,clip_value_max=0.05,name=None)\n",
        "        discriminator.trainable_weights[t].assign(y)\n",
        "\n",
        "        #tf.print(discriminator.trainable_weights[1])\n",
        "\n",
        "    \n",
        "      if i == (n_steps-1) :\n",
        "        fake_training_data = generator(x)\n",
        "        fake_output = discriminator(fake_training_data)\n",
        "        gen_loss = -tf.reduce_mean(fake_output)\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:39.056490Z",
          "start_time": "2019-05-14T06:31:39.049635Z"
        },
        "colab_type": "code",
        "id": "47sz8RMeSYb-",
        "colab": {}
      },
      "source": [
        "# exampled data for plotting results\n",
        "def plot_reconstruction(nex=8, zm=2):\n",
        "    samples = generator(tf.random.normal([train_x.shape[0], 1, 1, 64]))\n",
        "    fig, axs = plt.subplots(ncols=nex, nrows=1, figsize=(zm * nex, zm))\n",
        "    for axi in range(nex):\n",
        "        axs[axi].matshow(\n",
        "                    samples.numpy()[axi].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
        "                )\n",
        "        axs[axi].axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T06:31:39.152670Z",
          "start_time": "2019-05-14T06:31:39.058505Z"
        },
        "colab_type": "code",
        "id": "pKkEX9yBSYcB",
        "colab": {}
      },
      "source": [
        "# a pandas dataframe to save the loss information to\n",
        "losses = pd.DataFrame(columns = ['disc_loss', 'gen_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T07:04:26.791634Z",
          "start_time": "2019-05-14T07:04:17.126436Z"
        },
        "colab_type": "code",
        "id": "00dI2M4iSYcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "4dfff8d6f3274d0b8a3384bf2fe976e2",
            "8fd8c3363ea24223bedf2fb88d19f690",
            "1cf434a12c9f46318e9550e32740512f",
            "39e2a871f18c47a1b494ba2f86280672",
            "ac89cc7257f24a5d9ff6c1dd2966fb2e",
            "4b86b1bfcad143da98b86666d36bb872",
            "93c2668a9e394c88a320c55adf85968b",
            "950759505b61437ba559943a7e0a8cb5"
          ]
        },
        "outputId": "01b0787b-4670-43d6-fbb0-d509e71d9bb0"
      },
      "source": [
        "%%time\n",
        "start = time.time()\n",
        "n_epochs = 150\n",
        "for epoch in range(n_epochs):\n",
        "    # train\n",
        "    for batch, train_x in tqdm(\n",
        "        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\n",
        "    ):\n",
        "        train_step(train_x)\n",
        "  #      model.train(train_x)\n",
        "    # test on holdout\n",
        "    loss = []\n",
        "    for batch, test_x in tqdm(\n",
        "        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES\n",
        "    ):\n",
        "        loss.append(compute_loss(train_x))\n",
        "    losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
        "    # plot results\n",
        "    display.clear_output()\n",
        "    print(\n",
        "        \"Epoch: {} | disc_loss: {} | gen_loss: {}\".format(\n",
        "            epoch, losses.disc_loss.values[-1], losses.gen_loss.values[-1]\n",
        "        )\n",
        "    )\n",
        "    plot_reconstruction()\n",
        "\n",
        "time_to_train_gan = time.time()-start\n",
        "tf.print ('Time for the training is {} sec,'.format( time.time()-start))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 96 | disc_loss: 0.021251097321510315 | gen_loss: -0.4833492934703827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAABtCAYAAAAI5vRhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 1152x144 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dfff8d6f3274d0b8a3384bf2fe976e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=117), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-df3621c75be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start = time.time()\\nn_epochs = 150\\nfor epoch in range(n_epochs):\\n    # train\\n    for batch, train_x in tqdm(\\n        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\\n    ):\\n        train_step(train_x)\\n  #      model.train(train_x)\\n    # test on holdout\\n    loss = []\\n    for batch, test_x in tqdm(\\n        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES\\n    ):\\n        loss.append(compute_loss(train_x))\\n    losses.loc[len(losses)] = np.mean(loss, axis=0)\\n    # plot results\\n    display.clear_output()\\n    print(\\n        \"Epoch: {} | disc_loss: {} | gen_loss: {}\".format(\\n            epoch, losses.disc_loss.values[-1], losses.gen_loss.values[-1]\\n        )\\n    )\\n    plot_reconstruction()\\n\\ntime_to_train_gan = time.time()-start\\ntf.print (\\'Time for the training is {} sec,\\'.format( time.time()-start))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0fQ6OXgPf1",
        "colab_type": "text"
      },
      "source": [
        "# GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyBawwHIQOJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses.disc_loss.values) \n",
        "plt.ylabel(\"Loss\", fontsize=14, rotation=90)\n",
        "plt.xlabel(\"Iterations\", fontsize=14)\n",
        "plt.legend(['WGAN training loss'],\n",
        "           prop={'size': 14}, loc='upper right');\n",
        "plt.grid(True, which=\"both\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}